services:
  sample-validate:
    build:
      context: .
      dockerfile: docker/sut/rule_only/Dockerfile
    environment:
      PYTHONUNBUFFERED: "1"
      OLLAMA_HOST: ${OLLAMA_HOST:-http://host.docker.internal:11434}
      MODEL_NAME: ${MODEL_NAME:-qwen3:0.6b}
      SEED: ${SEED:-42}
      MAX_ITEMS: "5"
      TIER: ${TIER:-canonical}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: ["python", "-u", "-m", "benchmark.sample_validate"]
    volumes:
      - ./:/app
      - ./results:/app/results
      - ./datasets:/app/datasets:ro
      - ./benchmark:/app/benchmark:ro

  full-run:
    build:
      context: .
      dockerfile: docker/sut/rule_only/Dockerfile
    environment:
      PYTHONUNBUFFERED: "1"
      OLLAMA_HOST: ${OLLAMA_HOST:-http://host.docker.internal:11434}
      MODEL_NAME: ${MODEL_NAME:-qwen3:0.6b}
      SEED: ${SEED:-42}
      MAX_ITEMS: ${MAX_ITEMS:-100}
      TIER: ${TIER:-canonical}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: ["python", "-u", "-m", "benchmark.orchestrate"]
    volumes:
      - ./:/app
      - ./results:/app/results
      - ./datasets:/app/datasets:ro
      - ./benchmark:/app/benchmark:ro

  run-scenario:
    build:
      context: .
      dockerfile: docker/sut/rule_only/Dockerfile
    environment:
      PYTHONUNBUFFERED: "1"
      OLLAMA_HOST: ${OLLAMA_HOST:-http://host.docker.internal:11434}
      MODEL_NAME: ${MODEL_NAME:-qwen3:0.6b}
      SEED: ${SEED:-42}
      MAX_ITEMS: ${MAX_ITEMS:-100}
      TIER: ${TIER:-canonical}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: ["python", "-u", "-m", "benchmark.run", "--scenario", "baseline", "--out", "results/baseline"]
    volumes:
      - ./:/app
      - ./results:/app/results
      - ./datasets:/app/datasets:ro
      - ./benchmark:/app/benchmark:ro

  evaluate:
    build:
      context: .
      dockerfile: docker/sut/rule_only/Dockerfile
    command: ["python", "-u", "-c", "from pathlib import Path; import json; from benchmark.evaluate import evaluate_run; print(json.dumps(evaluate_run(Path('results/baseline/predictions')), indent=2))"]
    volumes:
      - ./:/app

  report:
    build:
      context: .
      dockerfile: docker/sut/rule_only/Dockerfile
    command: ["python", "-u", "-c", "from benchmark.report import generate_final_report; print(generate_final_report())"]
    volumes:
      - ./:/app
